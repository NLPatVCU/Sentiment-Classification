{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Naive Implementation of a Naive Bayes Classifier for Sentiment Analysis of WebMD Drug Reviews\n",
    "\n",
    "The NLTK NB Classifier was used in this work.  Code was modified from the tutorial at https://www.twilio.com/blog/2017/09/sentiment-analysis-python-messy-data-nltk.html for this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import packages we need\n",
    "\n",
    "import string\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import nltk.classify.util\n",
    "import nltk\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define needed functions\n",
    "\n",
    "def format_sentence(sent, stopwords=None):\n",
    "    filtered_words = []\n",
    "    # convert to lowercase\n",
    "    sent = sent.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "    #remove stopwords\n",
    "    if stopwords is not None:\n",
    "        com_list = sent.split()\n",
    "        for word in com_list:\n",
    "            if word not in stopwords:\n",
    "                filtered_words.append(word)\n",
    "        #sent = ' '.join(filtered_words)\n",
    "    \n",
    "    #return({word: True for word in nltk.word_tokenize(sent)})\n",
    "    return({word: True for word in filtered_words})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import reviews from csv file\n",
    "\n",
    "my_list = []\n",
    "with open('citalopram_effectivness.csv') as commentfile:\n",
    "    reader = csv.DictReader(commentfile)\n",
    "    for row in reader:\n",
    "        my_list.append({'comment': row['comment'], 'rating': row['rating']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg:152\n",
      "Pos:431\n",
      "Neutral:146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fact': True,\n",
       "  'great': True,\n",
       "  'other': True,\n",
       "  'sleepy': True,\n",
       "  'than': True,\n",
       "  'very': True},\n",
       " 'pos')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## split reviews up into a positive, negative, and neutral list\n",
    "\n",
    "pos_list=[]\n",
    "neg_list=[]\n",
    "neu_list=[]\n",
    "for c in my_list:\n",
    "    tmp_com = c['comment']\n",
    "    tmp_rating = c['rating']\n",
    "\n",
    "    #remove stop words\n",
    "    with open('./stopwords_long') as raw:\n",
    "        stopwords = raw.read().translate(str.maketrans(\"\", \"\", string.punctuation)).splitlines()\n",
    "        \n",
    "        if tmp_com != '':\n",
    "            if tmp_rating in ['1','2']:\n",
    "                neg_list.append((format_sentence(tmp_com, stopwords), 'neg'))\n",
    "            elif tmp_rating in ['4','5']:\n",
    "                pos_list.append((format_sentence(tmp_com, stopwords), 'pos'))\n",
    "            else:\n",
    "                neu_list.append(tmp_com)\n",
    "\n",
    "    \n",
    "print(\"Neg:\"+str(len(neg_list))+\"\\nPos:\"+str(len(pos_list))+\"\\nNeutral:\"+str(len(neu_list)))\n",
    "pos_list[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## print neutral entries to a file\n",
    "\n",
    "#with open('neutral.txt', 'w') as output_file:\n",
    "#    for i in neu_list:\n",
    "#        output_file.write(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 437 instances, test on 146 instances\n",
      "negcutoff 114 instances, poscutoff 323 instances\n"
     ]
    }
   ],
   "source": [
    "### create training and test sets\n",
    "\n",
    "## set the cutoffs\n",
    "negcutoff = math.floor(len(neg_list)*3/4)\n",
    "poscutoff = math.floor(len(pos_list)*3/4)\n",
    "\n",
    "train = neg_list[:negcutoff] + pos_list[:poscutoff]\n",
    "test = neg_list[negcutoff:] + pos_list[poscutoff:]\n",
    "print('train on %d instances, test on %d instances' % (len(train), len(test)))\n",
    "print('negcutoff %d instances, poscutoff %d instances' % (negcutoff, poscutoff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 437 instances, test on 146 instances\n",
      "neg_idx_train 114 instances, pos_idx_train 323 instances\n"
     ]
    }
   ],
   "source": [
    "## creates randomly chosen training and test sets\n",
    "\n",
    "import random\n",
    "neg_idx_train = sorted(random.sample(range(len(neg_list)), negcutoff))\n",
    "neg_train = [neg_list[i] for i in neg_idx_train]\n",
    "\n",
    "neg_idx_test = set(range(len(neg_list))) - set(neg_idx_train)\n",
    "neg_test = [neg_list[i] for i in neg_idx_test]\n",
    "\n",
    "\n",
    "pos_idx_train = sorted(random.sample(range(len(pos_list)), poscutoff))\n",
    "pos_train = [pos_list[i] for i in pos_idx_train]\n",
    "\n",
    "pos_idx_test = set(range(len(pos_list))) - set(pos_idx_train)\n",
    "pos_test = [pos_list[i] for i in pos_idx_test]\n",
    "\n",
    "train = neg_train + pos_train\n",
    "test = neg_test + pos_test\n",
    "\n",
    "wtrain = csv.writer(open ('citalopram_train.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "for label in train:\n",
    "    wtrain.writerows([label])\n",
    "\n",
    "wtest = csv.writer(open ('citalopram_test.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "for label in test:\n",
    "    wtest.writerows([label])\n",
    "\n",
    "\n",
    "print('train on %d instances, test on %d instances' % (len(train), len(test)))\n",
    "print('neg_idx_train %d instances, pos_idx_train %d instances' % (len(neg_idx_train), len(pos_idx_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7328767123287672\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', nltk.classify.util.accuracy(classifier, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 stomach = True              neg : pos    =     10.3 : 1.0\n",
      "                cymbalta = True              neg : pos    =      6.6 : 1.0\n",
      "                  hoping = True              neg : pos    =      6.6 : 1.0\n",
      "                    quit = True              neg : pos    =      6.2 : 1.0\n",
      "                   since = True              pos : neg    =      5.6 : 1.0\n",
      "                   years = True              pos : neg    =      5.4 : 1.0\n",
      "                terrible = True              neg : pos    =      5.1 : 1.0\n",
      "              absolutely = True              neg : pos    =      5.1 : 1.0\n",
      "                   happy = True              pos : neg    =      4.8 : 1.0\n",
      "                   bouts = True              neg : pos    =      4.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import neutral reviews\n",
    "\n",
    "with open('neutral.txt') as file:\n",
    "    toclass = file.readlines()\n",
    "len(toclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of possible mis-classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can see not improvement\n",
      "\n",
      "{'improvement': True}\n",
      "Classification: pos\n"
     ]
    }
   ],
   "source": [
    "## Negation\n",
    "print(toclass[9])\n",
    "print(format_sentence(toclass[9], stopwords))\n",
    "print('Classification: '+classifier.classify(format_sentence(toclass[9], stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still very depressed.\n",
      "\n",
      "{'very': True, 'depressed': True}\n",
      "Classification: pos\n"
     ]
    }
   ],
   "source": [
    "## Semantics\n",
    "print(toclass[29])\n",
    "print(format_sentence(toclass[29], stopwords))\n",
    "print('Classification: '+classifier.classify(format_sentence(toclass[29], stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have had rapid heart beat ,loss of appetite ,weight loss ,loss of sleep ,stomach pains, cramps in my feet or muscle cramps, frequent urination,  but it has helped my mood\n",
      "\n",
      "{'rapid': True, 'heart': True, 'beat': True, 'loss': True, 'appetite': True, 'weight': True, 'sleep': True, 'stomach': True, 'pains': True, 'cramps': True, 'feet': True, 'or': True, 'muscle': True, 'frequent': True, 'urination': True, 'helped': True, 'mood': True}\n",
      "Classification: neg\n"
     ]
    }
   ],
   "source": [
    "## Confusion of symptoms and end outcome\n",
    "print(toclass[32])\n",
    "print(format_sentence(toclass[32], stopwords))\n",
    "print('Classification: '+classifier.classify(format_sentence(toclass[32], stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does this cause mild stomach pain?\n",
      "\n",
      "{'mild': True, 'stomach': True, 'pain': True}\n",
      "Classification: neg\n"
     ]
    }
   ],
   "source": [
    "## Neutral question, not opinion\n",
    "print(toclass[55])\n",
    "print(format_sentence(toclass[55], stopwords))\n",
    "print('Classification: '+classifier.classify(format_sentence(toclass[55], stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples\n",
    "The second and third actually change their predicted class depending on whether or not you remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"I took the medication for depression, it did a great job, however I was always tired. I couldn't stay awake on my job, couldn't stay awake while driving. I was just putting myself in harm by taking that medicine. The sleepiness, never went away.\"\n",
    "print(classifier.classify(format_sentence(sent1, stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "sent2 = \"Can't stay awake always tired and doesn't seem to work for me I've had up to 40mg need to try a different tablet\"\n",
    "print(classifier.classify(format_sentence(sent2, stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "sent3 = \"I recently had to kick my son out of the house. I could hardly bare it. I couldn't get out of bed and cried every day. I was talked into taking Celexa by my DR. After 3-4 weeks, I did stop crying and could get out of bed. But seeing a counselor helped me the most and have come to terms with my crisis event. After 2.5 months, I have stopped taking Celexa. I talked to my pharmacist and the side effects (for me) were multiple and harsh. Nausea, dizziness, diarrhea and the worst was the trembling in my hands. I thought I was getting Parkinsons! Good luck to all with finding your happiness.\"\n",
    "print(classifier.classify(format_sentence(sent3, stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Swap\n",
    "The classifier above was trained on Citalopram drug reviews.  Lets test out how it will perform on Gilenya drug reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import Gilenya reviews\n",
    "\n",
    "gilenya_list = []\n",
    "with open('gilenya_effectivness.csv') as commentfile:\n",
    "    reader = csv.DictReader(commentfile)\n",
    "    for row in reader:\n",
    "        gilenya_list.append({'comment': row['comment'], 'rating': row['rating']})\n",
    "len(gilenya_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list = []\n",
    "for c in range(len(gilenya_list)):\n",
    "    tmp_c = gilenya_list[c]['comment']\n",
    "    tmp_r = gilenya_list[c]['rating']\n",
    "        \n",
    "    if tmp_r in ['1','2']:\n",
    "        d_list.append((format_sentence(tmp_c, stopwords), 'neg'))\n",
    "    if tmp_r in ['3','4','5']:\n",
    "        d_list.append((format_sentence(tmp_c, stopwords), 'pos'))\n",
    "        \n",
    "nltk.classify.util.accuracy(classifier, d_list)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the classifier performs better on the Gilenya reviews than it did on the Citalopram."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
